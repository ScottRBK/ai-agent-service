# AI Agent Service

A modern, intelligent AI Agent Service built with FastAPI that provides automated decision-making and AI-powered capabilities. Built with Docker, comprehensive logging, and production-ready features.

## âœ¨ Features

- **FastAPI Framework** - Modern, fast web framework with automatic API documentation
- **AI Agent Capabilities** - Intelligent automation and decision-making
- **Health Check Endpoints** - Built-in monitoring and status endpoints
- **Multi-Provider AI Support** - Azure OpenAI, Ollama with unified interface
- **MCP Integration** - Model Context Protocol for external tools
- **Tool Filtering** - Agent-specific permissions and authorization
- **Docker Support** - Multi-stage builds with development and production targets 
- **Environment Configuration** - Flexible settings with environment variable support
- **Structured Logging** - Comprehensive logging setup for debugging and monitoring
- **Type Safety** - Full type hints throughout the codebase
- **Auto-Generated Docs** - Interactive API documentation with Swagger UI and ReDoc
- **Hot Reload** - Development mode with automatic code reloading

## ğŸš€ Quick Start

### Using Docker (Recommended)

```bash
# Clone the repository
git clone https://github.com/ScottRBK/ai-agent-service
cd ai-agent-service

# Run in development mode
cd docker
docker-compose --profile dev up --build
```

The service will be available at:
- **API**: http://localhost:8001
- **Health Check**: http://localhost:8001/health
- **API Docs**: http://localhost:8001/docs
- **ReDoc**: http://localhost:8001/redoc

### Local Development

```bash
# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run the application
python -m app.main
```

## Software Architecture
![High Level Architecture](architecture.png "High Level Architecture")

## ğŸ“ Project Structure 

```
ai-agent-service/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ routes/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â””â”€â”€ health.py
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”‚   â””â”€â”€ agent_tool_manager.py    # Agent tool filtering
â”‚   â”‚   â”œâ”€â”€ providers/
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py                  # Base provider interface
â”‚   â”‚   â”‚   â”œâ”€â”€ azureopenapi.py          # Azure OpenAI (Responses API)
â”‚   â”‚   â”‚   â”œâ”€â”€ azureopenapi_cc.py       # Azure OpenAI (Chat Completions)
â”‚   â”‚   â”‚   â””â”€â”€ ollama.py                # Ollama provider
â”‚   â”‚   â””â”€â”€ tools/
â”‚   â”‚       â”œâ”€â”€ tool_registry.py         # Tool management
â”‚   â”‚       â””â”€â”€ function_calls/          # Built-in tools
â”‚   â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ models/
â”‚   â””â”€â”€ utils/
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_core/
â”‚   â”‚   â”œâ”€â”€ test_agents/                 # Agent unit tests
â”‚   â”‚   â”œâ”€â”€ test_providers/              # Provider tests
â”‚   â”‚   â””â”€â”€ test_tools/                  # Tool tests
â”‚   â””â”€â”€ test_integration/                # End-to-end tests
â”œâ”€â”€ agent_config.json                    # Agent configurations
â”œâ”€â”€ mcp.json                            # MCP server config
â””â”€â”€ requirements.txt
```

## ğŸ”§ Configuration

The application uses environment-based configuration with sensible defaults:

| Variable | Default | Description |
|----------|---------|-------------|
| `SERVICE_NAME` | "AI Agent Service" | Name of the service |
| `SERVICE_VERSION` | "1.0.0" | Version of the service |
| `HOST` | "0.0.0.0" | Server host address |
| `PORT` | 8000 | Server port |
| `LOG_LEVEL` | "DEBUG" | Logging level |

### Environment Files

Create a `.env` file in the `docker/` directory to override defaults:

```env
# docker/.env
PORT=8001
LOG_LEVEL=INFO
DEV_CONTAINER_NAME=my-agent-service
```

## ğŸ“¡ API Endpoints

### Root Endpoint
- **GET** `/` - Service information and status

### Health Check
- **GET** `/health` - Detailed health status with timestamp

### Documentation
- **GET** `/docs` - Interactive Swagger UI documentation
- **GET** `/redoc` - Alternative ReDoc documentation

### Example Response

```json
{
  "status": "healthy",
  "timestamp": "2024-01-01T12:00:00.000000",
  "service": "AI Agent Service",
  "version": "1.0.0"
}
```

## ğŸ³ Docker Usage

### Development Mode
```bash
cd docker
docker-compose --profile dev up --build
```

### Production Build
```bash
docker build -f docker/Dockerfile --target production -t ai-agent-service:latest .
docker run -p 8000:8000 ai-agent-service:latest
```

### Docker Environment Variables
```bash
# Override default port
docker run -e PORT=8001 -p 8001:8001 ai-agent-service:latest
```

## ğŸ¤– AI Agent & Tool Management

### Agent Configuration
Configure agent-specific tool access via `agent_config.json`:

```json
[
  {
    "agent_id": "research_agent",
    "allowed_regular_tools": ["get_current_datetime"],
    "allowed_mcp_servers": ["deepwiki", "fetch"],
    "allowed_mcp_tools": {
      "deepwiki": ["read_wiki_structure", "search_wiki"],
      "fetch": ["fetch_url"]
    }
  }
]
```

### MCP (Model Context Protocol) Integration
I have included two example MCP servers for examples
- **DeepWiki Server** - Interrogate information on Deepwiki page, https://docs.devin.ai/work-with-devin/deepwiki-mcp
- **Fetch Server** - An MCP server that provides web content fetching capabilities. This server enables LLMs to retrieve and process content from web pages, converting HTML to markdown for easier consumption 
- **Extensible** - Add custom MCP servers via `mcp.json`

### Tool Filtering
- **Agent-specific permissions** - Control which tools each agent can access
- **Regular tools** - Built-in functions like date/time, arithmetic, these are both just very basic examples 
- **MCP tools** - External server capabilities with proper authorization

## Provider Support

### Supported AI Providers
- **Azure OpenAI (Chat Completions)** - Full MCP integration
- **Azure OpenAI (Responses API)** - Full MCP integration  
- **Ollama** - Full MCP integration

### Provider Features
- **Tool calling** - Execute functions and MCP tools
- **Agent filtering** - Provider-agnostic tool management
- **Health monitoring** - Provider status and metrics
- **Error handling** - Robust error management

## ğŸ¤– Running Agents

### Quick Start with CLI Agent

Use the example script to run different agents with various providers:

```bash
# Run the research agent with Azure OpenAI
python examples/run_agent.py research_agent azure_openai_cc

# Run the data analysis agent with Ollama
python examples/run_agent.py data_agent ollama

# Run the MCP-only agent
python examples/run_agent.py mcp_agent azure_openai_cc
```

### Available Agents

| Agent | Description | Tools Available |
|-------|-------------|-----------------|
| `research_agent` | Research assistant with web access | datetime, deepwiki, fetch |
| `data_agent` | Data analysis specialist | datetime, arithmetic |
| `mcp_agent` | MCP tools only | deepwiki, fetch |
| `restricted_agent` | Limited access example | specific tools only |

### Available Providers

| Provider | Description | Use Case |
|----------|-------------|----------|
| `azure_openai_cc` | Azure OpenAI (Chat Completions) | Production, full features |
| `azure_openai` | Azure OpenAI (Responses API) | Legacy compatibility |
| `ollama` | Local Ollama provider | Development, offline |

### Example Session

```bash
$ python examples/run_agent.py research_agent azure_openai_cc

ğŸ¤– research_agent Agent Ready!
ğŸ› ï¸ Available tools: 6
ğŸ’¬ Type 'quit' to exit

You: What's the current time in Tokyo?
ğŸ¤” Thinking...
ğŸ¤– research_agent: The current time in Tokyo is 2025-01-16 15:30:45.

You: Research Python async programming
ğŸ¤” Thinking...
ğŸ¤– research_agent: I'll search for information about Python async programming...

You: quit
ğŸ‘‹ Goodbye!
```

### Agent Configuration

Agents are configured in `agent_config.json`:

```json
[
  {
    "agent_id": "research_agent",
    "allowed_regular_tools": ["get_current_datetime"],
    "allowed_mcp_servers": ["deepwiki", "fetch"],
    "allowed_mcp_tools": {
      "deepwiki": ["read_wiki_structure", "search_wiki"],
      "fetch": ["fetch_url"]
    }
  }
]
```

### Troubleshooting

**Agent not found:**
- Check `agent_config.json` exists and is valid JSON
- Verify agent_id matches configuration

**Provider not available:**
- Check provider credentials and configuration
- Ensure required environment variables are set

**Tools not working:**
- Verify MCP servers are running (for MCP tools)
- Check tool permissions in agent configuration

## ğŸ§ª Testing

### Test Coverage
- **75+ tests** including unit and integration tests
- **Agent tool filtering** - Comprehensive permission testing
- **MCP integration** - End-to-end tool execution
- **Provider compatibility** - All providers tested

### Running Tests
```bash
# Run all tests
pytest tests/

# Run specific test categories
pytest tests/test_core/test_agents/     # Agent unit tests
pytest tests/test_integration/          # Integration tests

# Run with coverage
pytest tests/ --cov=app --cov-report=html
```

### Test Examples
```bash
# Test agent tool filtering
pytest tests/test_integration/test_agent_tool_filtering_integration.py

# Test MCP integration
pytest tests/test_integration/test_basic_chat_agent_integration.py
```

## ğŸ› ï¸ Development

### Adding New Endpoints

1. Create a new route file in `app/api/routes/`
2. Define your Pydantic models in `app/models/`
3. Include the router in `app/main.py`

Example:
### Using Agents with MCP Tools

```python
from app.core.agents.agent_tool_manager import AgentToolManager
from app.core.providers.manager import ProviderManager

# Create agent with specific tool access
agent_manager = AgentToolManager("research_agent")

# Get available tools (regular + MCP)
tools = await agent_manager.get_available_tools()

# Use with any provider
provider = ProviderManager().get_provider("azure_openai_cc")
response = await provider.send_chat(
    context=[{"role": "user", "content": "What's the current time?"}],
    model="gpt-4",
    instructions="You are a helpful assistant.",
    agent_id="research_agent"
)
```

### Hot Reload
Development mode automatically reloads on code changes:
```bash
docker-compose --profile dev up
```

## ğŸ“¦ Dependencies

Key dependencies include:
- **FastAPI** - Modern web framework
- **FastMCP** - Modern MCP Integration framework
- **Uvicorn** - ASGI server with uvloop for performance
- **Pydantic** - Data validation and settings management
- **Pydantic-settings** - Environment-based configuration
- **Pytest** - Testing framework

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ†˜ Support

For questions or issues:
1. Check the [API documentation](http://localhost:8001/docs) when running locally
2. Review the logs: `docker logs <container-name>`
3. Open an issue in this repository

---

**Happy coding!** ğŸš€ 